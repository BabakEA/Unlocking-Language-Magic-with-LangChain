{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width: 100%; border-collapse: collapse;\">\n",
    "    <tr>\n",
    "        <td style=\"padding: 5px; text-align: left; color: blue;\">\n",
    "            <h1>Langchain</h1>\n",
    "            <h2>Introduction to Chain of Commands</h2>\n",
    "            <h3>Date: 2024-05-04</h3>\n",
    "            <h3>Author: Babak EA</h3>\n",
    "            <h3>GitHub: <a href=\"https://github.com/BabakEA\">BabakEA</a></h3>\n",
    "            <h3>LinkedIn: <a href=\"https://www.linkedin.com/in/babak-emami\">Babak Emami</a></h3>\n",
    "        </td>\n",
    "        <td style=\"width: 70%;  \">\n",
    "            <img src=\"./Images/Designer_5.png\" alt=\"Introduction to LangChain\" width=\"620\">\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RSTxnoIozRN"
   },
   "outputs": [],
   "source": [
    "#!pip -q install -U openai langchain huggingface_hub langchain_openai crewai langchain-groq duckduckgo-search\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json, os, sys\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "#from openai.api_request import APIRequestError\n",
    "\n",
    "import langchain\n",
    "#from langchain.llms import OpenAI\n",
    "#from langchain_openai import OpenAI\n",
    "from langchain import PromptTemplate, FewShotPromptTemplate\n",
    "from langchain import PromptTemplate ### prompt templet\n",
    "\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "## Langchain_openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "#### Groq--> Lama3\n",
    "from langchain_groq import ChatGroq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang_Study:\n",
    "    def __init__(self,secret_path:str):\n",
    "        self._secret_path=secret_path\n",
    "        \n",
    "    def Secret(self):\n",
    "    #STR_Secret=[x for x in os.listdir(f\"./{Path}/\") if Keyword in x.lower()][0]\n",
    "        with open(self._secret_path) as config_file:\n",
    "            config_data = json.load(config_file)\n",
    "            self.OPENAI_API_KEY = config_data.get(\"api_key\")\n",
    "            self.HUGGINGFACEHUB_API_TOKEN = config_data[\"huggingface\"].get(\"Read\")\n",
    "            self.GROQ_API_KEY=config_data[\"groq\"].get(\"Api\")\n",
    "            os.environ['OPENAI_API_KEY'] = self.OPENAI_API_KEY\n",
    "            os.environ['HUGGINGFACEHUB_API_TOKEN'] = self.HUGGINGFACEHUB_API_TOKEN \n",
    "            os.environ[\"GROQ_API_KEY\"]=self.GROQ_API_KEY\n",
    "            \n",
    "    def get_supported_models(self):\n",
    "        api_key = os.environ['OPENAI_API_KEY']\n",
    "        headers = {'Authorization': f'Bearer {api_key}'}\n",
    "        response = requests.get('https://api.openai.com/v1/models', headers=headers)\n",
    "        models = response.json()\n",
    "        self.open_ai_model_lists=[model['id'] for model in models['data']]\n",
    "        return [model['id'] for model in models['data']]\n",
    "\n",
    "\n",
    "    def Open_AI_Client(self,temperature=0.9,max_tokens=5000):\n",
    "        self.client = OpenAI(\n",
    "        # This is the default and can be omitted\n",
    "        api_key=self.OPENAI_API_KEY,)\n",
    "    def Groq_LLAMA3(self,temperature=0.9,max_tokens=5000):\n",
    "        self.LAMA3 = ChatGroq(\n",
    "                api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "                model=\"llama3-70b-8192\",\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens,\n",
    "                max_retries=3)\n",
    "    def Langchain_LLM(self,temperature=0.9,max_tokens=5000):\n",
    "        self.Lang_OPENAI = chat = ChatOpenAI(\n",
    "            model_name='gpt-3.5-turbo-16k',\n",
    "            temperature = temperature,\n",
    "            openai_api_key = os.environ['OPENAI_API_KEY'],         \n",
    "            max_tokens=max_tokens)\n",
    "    \n",
    "    def Promt_temp(self):\n",
    "        system_template = \"\"\"\n",
    "        You are a writer designed to write a creative, funny short story using the user's keywords.\n",
    "        {user_keywords}\n",
    "        \"\"\"\n",
    "\n",
    "        self.prompt_template = PromptTemplate(\n",
    "            input_variables=[\"user_keywords\"], \n",
    "            template=system_template)\n",
    "    \n",
    "\n",
    "    def __call__(self):\n",
    "        self.Secret()\n",
    "        self.Open_AI_Client()\n",
    "        self.Groq_LLAMA3()\n",
    "        self.Langchain_LLM()##Lang_OPENAI\n",
    "    \n",
    "              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9iIacDfgpB2M"
   },
   "outputs": [],
   "source": [
    "Lang_study=Lang_Study(secret_path=\"./Secret/secret.json\")\n",
    "Lang_study()\n",
    "# Lang_study.Secret()\n",
    "# Lang_study.Open_AI_Client()\n",
    "# Lang_study.Groq_LLAMA3()\n",
    "# Lang_study.Langchain_LLM()##Lang_OPENAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dall-e-3',\n",
       " 'whisper-1',\n",
       " 'davinci-002',\n",
       " 'gpt-3.5-turbo-1106',\n",
       " 'dall-e-2',\n",
       " 'gpt-3.5-turbo-16k',\n",
       " 'tts-1-hd-1106',\n",
       " 'tts-1-hd',\n",
       " 'gpt-4',\n",
       " 'gpt-4-turbo-2024-04-09',\n",
       " 'gpt-4-0613',\n",
       " 'gpt-4-turbo',\n",
       " 'gpt-4-vision-preview',\n",
       " 'gpt-3.5-turbo',\n",
       " 'gpt-3.5-turbo-instruct-0914',\n",
       " 'gpt-3.5-turbo-instruct',\n",
       " 'gpt-4-1106-vision-preview',\n",
       " 'gpt-3.5-turbo-0125',\n",
       " 'gpt-4-0125-preview',\n",
       " 'tts-1',\n",
       " 'gpt-3.5-turbo-0301',\n",
       " 'babbage-002',\n",
       " 'gpt-4-turbo-preview',\n",
       " 'tts-1-1106',\n",
       " 'gpt-4-1106-preview',\n",
       " 'text-embedding-3-large',\n",
       " 'text-embedding-3-small',\n",
       " 'text-embedding-ada-002',\n",
       " 'gpt-3.5-turbo-0613',\n",
       " 'gpt-3.5-turbo-16k-0613']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lists_of_openai_models:\n",
    "Lang_study.get_supported_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KB9qA8bpxgJ"
   },
   "source": [
    "## Plain Conditional Generation\n",
    "\n",
    "### First with OpenAI GPT3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-lzO5PfUpwfv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was a dark and stormy night, and Max found himself trapped in a subway station as the rain poured down outside. He sighed and cursed his luck as he watched the water gush down the steps, turning the stairs into a small waterfall.\n",
      "\n",
      "Just as he was about to resign himself to a long, wet wait, he noticed a small sign pointing towards an underground ice cream shop. His eyes lit up in excitement and he quickly made his way over, figuring that if he had to be stuck in a subway station, he might as well enjoy some ice cream while he waited for the rain to stop.\n",
      "\n",
      "As he entered the shop, he was greeted by the sight of a variety of delicious flavors, from classic vanilla to exotic mango and passionfruit. He eagerly ordered a double scoop of chocolate fudge and cookies n' cream, figuring that the rainy night called for some indulgence.\n",
      "\n",
      "As he sat at a rickety table, enjoying his ice cream, he noticed a man at the counter ordering a beer. Max couldn't help but chuckle at the thought of enjoying a cold one in a subway ice cream shop. The man caught his eye and raised his bottle in a silent toast, and Max couldn't help but raise his ice cream\n"
     ]
    }
   ],
   "source": [
    "System_Prompt=\"You are a writer designed to write a creative, funny short story using the user's keywords.\"\n",
    "User_Prompt=\"subway,rain,icecream,beer\"\n",
    "raw_data = Lang_study.client.chat.completions.create(\n",
    "                    messages=[\n",
    "                        {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\":System_Prompt,\n",
    "                        },\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": User_Prompt,\n",
    "                        }\n",
    "                    ],\n",
    "                    model=\"gpt-3.5-turbo-1106\",\n",
    "                    max_tokens=250,)\n",
    "text = raw_data.choices[0].message.content \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xidOhWp7rk_5"
   },
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dWFJY6-Qrm0L"
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "system_template = \"\"\"\n",
    "You are a writer designed to write a creative, funny short story using the user's keywords.\n",
    "{user_keywords}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"user_keywords\"], \n",
    "    template=system_template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "iQ0EEAywYkAb"
   },
   "outputs": [],
   "source": [
    "User_Prompt_1=\"subway,rain,icecream,beer\"\n",
    "User_Prompt_2=\"camera, photographt, bike, 5 dollar bill\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain uses Open_AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emami\\anaconda3\\envs\\NLP\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time in a small, vibrant town called Sunnyville, there lived a young and aspiring photographer named Max. Armed with his trusty camera, Max had a knack for capturing the most extraordinary and hilarious moments of everyday life.\n",
      "\n",
      "One sunny afternoon, as Max was riding his bike through the busy streets of Sunnyville, he noticed a peculiar sight. A 5-dollar bill was fluttering in the wind right in front of him. Max's eyes widened with excitement. \"Oh, the photo opportunities that await!\" he thought gleefully.\n",
      "\n",
      "Quickly leaping off his bike, Max retrieved the bill and looked around, searching for the perfect place to snap a photo. Spotting a group of pigeons huddled together on a nearby bench, he couldn't resist his creative instincts. He carefully placed the 5-dollar bill next to the birds and began snapping away.\n",
      "\n",
      "Unbeknownst to Max, a mischievous squirrel named Nutty was observing his every move. Nutty was the local prankster, always finding ways to get into hilarious shenanigans. Sensing an opportunity for mischief, Nutty devised a plan.\n",
      "\n",
      "As Max was engrossed in capturing the perfect shot, Nutty stealthily approached, grabbed the 5-dollar bill, and darted off into a nearby park. Max noticed the commotion and quickly hopped back onto his bike, determined to retrieve his beloved prop.\n",
      "\n",
      "A wild chase ensued! Max pedaled tirelessly, weaving through the park, giving it his all to catch up to the elusive squirrel. People passing by cheered him on, amused by the spectacle unfolding before their eyes. They even began to join Max in the pursuit, forming an impromptu bike brigade.\n",
      "\n",
      "With the entire town in tow, Max finally cornered Nutty near a majestic tree. The squirrel looked up at Max with mischievous eyes and a smug expression. Max couldn't help but laugh. He'd been hoping for an extraordinary photograph, but what he had gotten was a whole adventure instead.\n",
      "\n",
      "As the crowd erupted in laughter, Max vowed to photograph Nutty someday, capturing his cheeky antics for all to enjoy. And so, Sunnyville gained a new local legendâ€”the story of the great chase between Max and Nutty, forever immortalized in the town's funniest photographs.\n",
      "\n",
      "From that day on, Max's camera captured not only moments but also the true essence of the town, the laughter, and the absurdity of everyday life. And at the heart of it all, a 5-dollar bill, a bike, and a whimsical squirrel became the symbol of Sunnyville's joyful spirit.\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=Lang_study.Lang_OPENAI,\n",
    "                 prompt=prompt_template)\n",
    "print(chain.run(User_Prompt_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain uses LLAMA3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What a intriguing combination! Here's a short story that weaves these keywords into a hilarious and creative tale:\n",
      "\n",
      "**\"The Great Bike Camera Caper\"**\n",
      "\n",
      "Meet Jake, a struggling photographer with a passion for capturing the perfect shot. His trusty bike, Bertha, was his mode of transportation and mobile studio all in one. With his camera strapped to the handlebars, Jake would pedal around the city, snapping pics of everything from street performers to street food.\n",
      "\n",
      "One fateful day, while Jake was pedaling through the park, a gust of wind swept a crumpled 5-dollar bill out of a passerby's hand. The bill danced in the air, leading Jake on a merry chase as he pedaled after it, camera clicking away. The bill twirled and fluttered, teasing Jake until it finally came to rest on a nearby bench.\n",
      "\n",
      "As Jake dismounted to retrieve the bill, he noticed an intriguing scene unfolding before his lens. A group of mischievous squirrels had commandeered a vendor's cart, making off with a stash of juicy nuts. Jake's photographer instincts kicked in, and he began snapping away, Bertha patiently waiting by his side.\n",
      "\n",
      "The resulting photos were pure magic: squirrels in mid-heist, their beady eyes shining with glee. Jake knew he had a goldmine on his hands. He pedaled back to his makeshift studio, a converted garage in his friend's backyard, to develop the film.\n",
      "\n",
      "The next morning, Jake's phone was flooded with calls from local news outlets and animal-loving enthusiasts. His squirrel heist photos were an instant sensation, with offers pouring in from national magazines and even a popular morning talk show.\n",
      "\n",
      "As Jake basked in the glory of his unexpected fame, he couldn't help but glance at Bertha, his trusty bike, now proudly displaying a custom license plate that read \"CAMERABIKE.\" The 5-dollar bill, now framed and mounted on his studio wall, served as a reminder that sometimes, a little bit of luck and a lot of creativity can lead to a shot of a lifetime.\n",
      "\n",
      "I hope you enjoyed the story!\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "Lang_study.LAMA3 #### is our LLM defined in the class\n",
    "\n",
    "chain = LLMChain(llm=Lang_study.LAMA3,\n",
    "                 prompt=prompt_template)\n",
    "print(chain.run(User_Prompt_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3aiOsgwJX_Ol"
   },
   "source": [
    "## with Few Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a2AncvoJxON6"
   },
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, FewShotPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2WOFpG-RxOVb"
   },
   "outputs": [],
   "source": [
    "# First, create the list of few shot examples.\n",
    "# examples = [\n",
    "#   {\"Dish_Name\": \"Chicken Alfredo\", \"ingredients\": [\"Pasta\", \"Chicken breast\", \"Cream\", \"Parmesan cheese\", \"Garlic\", \"Butter\"],\n",
    "#   \"Story\":[\"Tasty but dangerouse,  you will getting fat by eatting every day\"]},\n",
    "#   {\"Dish_Name\": \"Mac and Cheese\", \"ingredients\": [\"Pasta\", \"Cheese\", \"Milk\", \"Butter\"],\n",
    "#   \"Story\":[\"Tasty but dangerouse,  you may need new pants after two burger, I told you\"]},\n",
    "# ]\n",
    "\n",
    "examples = [\n",
    "  {\"Dish_Name\": \"Chicken Alfredo\", \n",
    "   \"Ingredients\": [\"Pasta\", \"Chicken breast\", \"Cream\", \"Parmesan cheese\", \"Garlic\", \"Butter\"],\n",
    "   \"Funny Blurb\": [\"So creamy, you'll need a bigger spoon (and pants)!\"]},\n",
    "  {\"Dish_Name\": \"Mac and Cheese\",\n",
    "   \"Ingredients\": [\"Pasta\", \"Cheese\", \"Milk\", \"Butter\"],\n",
    "   \"Funny Blurb\": [\"Cheese heaven! Warning: May cause uncontrollable happiness.\"]},  # Optional: Warning Label twist\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qkDsAyF3xS7b"
   },
   "outputs": [],
   "source": [
    "# Next, we specify the template to format the examples we have provided.\n",
    "# We use the `PromptTemplate` class for this.\n",
    "example_formatter_template = \"\"\"\n",
    "Dish_Name: {Dish_Name}\n",
    "Ingredients: {Ingredients}\\n\n",
    "Did you know: {Funny Blurb}\\n\n",
    "\"\"\"\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"name\", \"ingredients\", \"Funny Blurb\"],\n",
    "    template=example_formatter_template,\n",
    ")\n",
    "\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"We just learned about some delicious dishes! Can you guess the ingredients for the following recipe?\",\n",
    "    suffix=\"Dish_Name: {input},\\n Ingredients: ,\\n Did you know:\",\n",
    "    input_variables=[\"input\"],\n",
    "    example_separator=\"\\n---\\n\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We just learned about some delicious dishes! Can you guess the ingredients for the following recipe?\n",
      "---\n",
      "\n",
      "Dish_Name: Chicken Alfredo\n",
      "Ingredients: ['Pasta', 'Chicken breast', 'Cream', 'Parmesan cheese', 'Garlic', 'Butter']\n",
      "\n",
      "Did you know: [\"So creamy, you'll need a bigger spoon (and pants)!\"]\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "Dish_Name: Mac and Cheese\n",
      "Ingredients: ['Pasta', 'Cheese', 'Milk', 'Butter']\n",
      "\n",
      "Did you know: ['Cheese heaven! Warning: May cause uncontrollable happiness.']\n",
      "\n",
      "\n",
      "---\n",
      "Dish_Name: Macaroni,\n",
      " Ingredients: ,\n",
      " Did you know:\n"
     ]
    }
   ],
   "source": [
    "print(few_shot_prompt.format(input=\"Macaroni\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love a good guessing game!\n",
      "\n",
      "For the pepperoni pizza, I'm going to take a stab at the ingredients:\n",
      "\n",
      "Dish_Name: pepperoni pizza,\n",
      "Ingredients: ['Pizza dough', 'Tomato sauce', 'Mozzarella cheese', 'Pepperoni', 'Oregano', 'Basil']\n",
      "\n",
      "Am I close?\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=Lang_study.LAMA3,\n",
    "                 prompt=few_shot_prompt)\n",
    "print(chain.run(\"pepperoni pizza\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pStpc2HIFY-9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
